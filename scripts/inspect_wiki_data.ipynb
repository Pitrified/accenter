{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open a wiki file and learn something\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download raw data from:\n",
    "https://kaikki.org/dictionary/French/index.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record structure\n",
    "\n",
    "### Word: `word`\n",
    "\n",
    "It's the word.\n",
    "\n",
    "### Part of speech: `pos`\n",
    "\n",
    "We can get a set of good pos to use.\n",
    "\n",
    "### Meaning of the word: `senses`\n",
    "\n",
    "Can be more than one (it's a list).\n",
    "\n",
    "`glosses`: The meaning of the word, also a list.\n",
    "`raw_glosses`: A more informative definition.\n",
    "`examples`: Examples.\n",
    "\n",
    "Each `sense` has a `categories` list,\n",
    "that can be useful for clustering words\n",
    "or to train by topic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent words\n",
    "\n",
    "1. Get the big corpus.\n",
    "1. For each word, get the non inflected version.\n",
    "1. Compute freq lol you are done.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fol = Path(\".\").absolute().parent / \"dataset\"\n",
    "\n",
    "wiki_fn_word_forms = \"kaikki.org-dictionary-French-words.json\"\n",
    "wiki_fn_non_inflected_senses = \"kaikki.org-dictionary-French-all-no-wFNY2q.json\"\n",
    "\n",
    "# wiki_fp = dataset_fol / wiki_fn_word_forms\n",
    "wiki_fp = dataset_fol / wiki_fn_non_inflected_senses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accent = set(\"àÀâÂéÉèÈêÊëËîÎïÏœŒôÔùÙûÛüÜçÇ\")\n",
    "print(accent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_pos = {\n",
    "    # \"\",\n",
    "    # '<i class=\"Jpan mention\" lang=\"ja\">かみかぜ</i> (kamikaze, “suicide flyer”, literally “divine wind”)',\n",
    "    # 'Modern French <i class=\"Latn mention\" lang=\"fr\">chair</i>',\n",
    "    # \"a\",\n",
    "    # \"a commune in Normandy, France\",\n",
    "    # \"a restoration of the Latin 3rd-person-singular -t\",\n",
    "    # \"abbrev\",\n",
    "    # \"ablative\",\n",
    "    # \"accusative plural\",\n",
    "    \"adj\",\n",
    "    # \"adjectival suffix\",\n",
    "    \"adjective\",\n",
    "    # \"adjective-forming suffix\",\n",
    "    \"adv\",\n",
    "    \"adverb\",\n",
    "    # \"affirmative particle\",\n",
    "    # \"affix\",\n",
    "    # \"an anchovy-based condiment\",\n",
    "    # \"an apocopic form of la, la before a vowel\",\n",
    "    \"article\",\n",
    "    # \"augmentative suffix\",\n",
    "    # \"character\",\n",
    "    # \"conj\",\n",
    "    # \"det\",\n",
    "    # \"dialectal\",\n",
    "    # \"diminutive ending\",\n",
    "    # \"diminutive suffix\",\n",
    "    # \"first-person plural present indicative ending\",\n",
    "    # 'from an Illyrian word probably from Proto-Indo-European <i class=\"Latinx mention\" lang=\"ine-pro\">*sab-</i> (“taste”)',\n",
    "    # \"infix\",\n",
    "    # \"instrumental suffix\",\n",
    "    # \"intensifier\",\n",
    "    # \"interfix\",\n",
    "    # \"interjection used in deer-hunting\",\n",
    "    # \"intj\",\n",
    "    # \"n\",\n",
    "    \"name\",\n",
    "    # \"name of a Celtic tribe in Southern Germany, which later emigrated to Gaul\",\n",
    "    # \"nominal suffix\",\n",
    "    \"noun\",\n",
    "    # \"noun suffix\",\n",
    "    \"nouns\",\n",
    "    \"num\",\n",
    "    # \"onomatopoeia of the lowing of cattle\",\n",
    "    \"particle\",\n",
    "    # \"past participle of dire (“to say”)\",\n",
    "    # \"past passive participle\",\n",
    "    \"phrase\",\n",
    "    # \"postp\",\n",
    "    \"prefix\",\n",
    "    \"prep\",\n",
    "    \"prep_phrase\",\n",
    "    \"pron\",\n",
    "    # \"pronounced /le‿ʁital(jɛ̃)/\",\n",
    "    \"proverb\",\n",
    "    # \"punct\",\n",
    "    # \"reflexive pronoun\",\n",
    "    # \"second-person singular\",\n",
    "    # \"stem libr-\",\n",
    "    # \"suffix\",\n",
    "    # \"suffix added to noun stems to form adjectives\",\n",
    "    # \"suffix added to verbal stems forming neuter nouns denoting the result of, a particular instance of, or the object of an action\",\n",
    "    # \"suffix denoting occupation\",\n",
    "    # \"suffix forming adjectives from nouns\",\n",
    "    # \"suffix forming adjectives meaning ‘belonging to, relating to’\",\n",
    "    # \"suffix forming augmentatives\",\n",
    "    # \"suffix forming diminutives\",\n",
    "    # \"suffix forming infinitives of first-conjugation verbs\",\n",
    "    # \"suffix forming nouns usually denoting diseased conditions\",\n",
    "    # \"suffix meaning ‘of or pertaining to’\",\n",
    "    # \"suffix with the sense ‘relating’ to forming adjectives\",\n",
    "    # \"surname\",\n",
    "    # \"symbol\",\n",
    "    # \"v\",\n",
    "    \"verb\",\n",
    "    \"verb and noun\",\n",
    "}\n",
    "len(good_pos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_object(obj, level, seen_keys, seen_pos):\n",
    "    # pad = \"\\t\" * level + str(level) + \": \"\n",
    "    if isinstance(obj, dict):\n",
    "        for key in obj:\n",
    "            # print(f\"{pad}opening {key=} {obj[key]=}\")\n",
    "            seen_keys.add(key)\n",
    "            if key == \"pos\":\n",
    "                seen_pos.add(obj[key])\n",
    "            walk_object(obj[key], level + 1, seen_keys, seen_pos)\n",
    "\n",
    "    elif isinstance(obj, list):\n",
    "        for el in obj:\n",
    "            # print(f\"{pad}traversing {el}\")\n",
    "            walk_object(el, level + 1, seen_keys, seen_pos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "One record per line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words_data = []\n",
    "with wiki_fp.open() as wf:\n",
    "    for line in wf:\n",
    "        word_data = json.loads(line)\n",
    "        words_data.append(word_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_keys = [\n",
    "    \"categories\",\n",
    "    \"form_of\",\n",
    "    \"pos\",\n",
    "    \"senses\",\n",
    "    \"word\",\n",
    "]\n",
    "\n",
    "for word_data in words_data:\n",
    "\n",
    "    # only keep words with good pos\n",
    "    if word_data[\"pos\"] not in good_pos:\n",
    "        continue\n",
    "\n",
    "    # keep only some keys in the word record\n",
    "    word_data_keys = list(word_data.keys())\n",
    "    for word_data_key in word_data_keys:\n",
    "        if word_data_key not in word_data:\n",
    "            del word_data[word_data_key]\n",
    "\n",
    "    # remove useless info in categories\n",
    "    # (useless if you have a graph of cats)\n",
    "    for sense in word_data[\"senses\"]:\n",
    "        if \"categories\" not in sense:\n",
    "            continue\n",
    "        for cat in sense[\"categories\"]:\n",
    "            cat_keys = list(cat.keys())\n",
    "            for cat_key in cat_keys:\n",
    "                if cat_key != \"name\":\n",
    "                    del cat[cat_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort(ish) the words\n",
    "# one word can have more than one pos\n",
    "words_data_sort = sorted(words_data, key=lambda x: x[\"word\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect keys and pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_keys = set()\n",
    "seen_pos = set()\n",
    "\n",
    "for word_data in words_data:\n",
    "    walk_object(word_data, level=0, seen_keys=seen_keys, seen_pos=seen_pos)\n",
    "\n",
    "len(seen_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_pos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze some words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_acc_data = []\n",
    "word_search = []\n",
    "\n",
    "for word_data in words_data_sort:\n",
    "    word = word_data[\"word\"]\n",
    "\n",
    "    word_letters = set(word)\n",
    "    is_accent = accent.intersection(word_letters)\n",
    "    if is_accent:\n",
    "        words_acc_data.append(word_data)\n",
    "        # print(f\"accent! {word}\")\n",
    "        # break\n",
    "\n",
    "    # word with a space\n",
    "    # if \" \" in word:\n",
    "    #     print(f\"found! {word}\")\n",
    "    #     break\n",
    "\n",
    "    # the_word = \"abîme\"\n",
    "    # the_word = \"abime\"\n",
    "    # the_word = \"abimes\"\n",
    "    # the_word = \"angariés\"\n",
    "    # the_word = \"angaries\"\n",
    "    # the_word = \"arrière\"\n",
    "    the_word = \"Alexia\"\n",
    "    if word == the_word:\n",
    "        print(f\"found! {word} {word_data['pos']}\")\n",
    "        word_search.append(word_data)\n",
    "\n",
    "    # if word_data[\"pos\"] == \"name\":\n",
    "    #     print(f\"found! {word} {word_data['pos']}\")\n",
    "    #     break\n",
    "\n",
    "\n",
    "print(f\"{len(words_acc_data)=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(word_search[0], width=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ri = randint(0, len(words_data_sort) - 1)\n",
    "# word_data = words_data_sort[ri]\n",
    "# print(f\"{ri=} {word_data['word']}\")\n",
    "# pprint(word_data, width=150)\n",
    "\n",
    "ri = randint(0, len(words_acc_data) - 1)\n",
    "acc_data = words_acc_data[ri]\n",
    "print(f\"{ri=} {acc_data['word']}\")\n",
    "pprint(acc_data, width=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # output file\n",
    "# wiki_out_fn = \"kaikki.org-dictionary-French-all-no-filter.json\"\n",
    "# wiki_out_fp = dataset_fol / wiki_out_fn\n",
    "# print(f\"{wiki_out_fp}\")\n",
    "# # build all the records\n",
    "# out_str = []\n",
    "# for word_data in words_data_sort:\n",
    "#     word_str = json.dumps(word_data)\n",
    "#     out_str.append(word_str)\n",
    "# # write out the records\n",
    "# dump_str = \"\\n\".join(out_str)\n",
    "# wiki_out_fp.write_text(dump_str)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56fddae659bb42062d07dbb89391b2c426532002bd0fbd34249c182257405271"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
